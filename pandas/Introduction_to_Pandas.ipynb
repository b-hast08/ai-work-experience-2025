{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <u>Introduction to Pandas</u>\n",
    "\n",
    "\n",
    "Pandas is a Python package that is used for cleaning, investigating and analysing tabular datasets. \n",
    "\n",
    "In Pandas, you can import a dataset in the form of a 'DataFrame' which is a table of data that can then be manipulated to help you complete the tasks you have set yourself. \n",
    "\n",
    "In this notebook, we will work through some simple examples of features in Pandas to help you with your data analysis in Python! \n",
    "\n",
    "The first step is importing the Pandas package itself...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Importing the Pandas Package**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To import Pandas into your working area run the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ```import pandas``` part of this code imports the ```pandas``` package.\n",
    "\n",
    "The ```as pd``` part of this sets ```pd``` as an alias for ```pandas``` to save you having to write out ```pandas``` in full everytime you call a function from the package into your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### **Importing a Dataset Using ```pd.read_csv()```**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "The ```pd.read_csv()``` function can be used to import a dataset from a csv file into a Pandas Dataframe.\n",
    "\n",
    "You do this by running the example command:\n",
    "- ```df = pd.read_csv(path)```\n",
    "\n",
    "Where:\n",
    "- ```df``` is the name you give the Dataframe object within your Python code\n",
    "- ```path``` is the string of the file path to your csv file that you want to import."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, import the *Iris* dataset using the path: ```'iris.csv'```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import the Iris Dataset in this cell\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### **Using ```df.head()```**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "```df.head()``` can be used to display the first n number of rows found within the Pandas DataFrame. \n",
    "\n",
    "As a default, if no value of n is passed, the function will return the first 5 rows of the DataFrame (assuming ```df``` has already been defined as a Pandas DataFrame from Cell 2)\n",
    "\n",
    "For example:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mhead(n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, type the code that will display the first 10 rows of the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first 10 rows of the Iris Dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, if you define n as a negative number (for example, ```df.head(n=-6)```) the last n rows of the dataframe will be displayed. In this example, the final 6 rows would be displayed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Describing your DataFrame - some useful functions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas uses some simple functions to make understanding and describing your DataFrame very easy. \n",
    "\n",
    "The first of these functions is the ```df.shape``` function. \n",
    "\n",
    "This function returns the shape of your dataframe in the format ```(rows, columns)```. Try it by running ```df.shape``` below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the shape of the iris dataframe?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we have the ```df.describe()``` function. This function returns the summary statistics for each column found within the dataframe and returns them in a separate dataframe. Try it by running ```df.describe()``` below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe the iris dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These functions are great for quickly understanding the size and distribution of the values within your DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Column-wise operations on Pandas DataFrame**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can perform operations on entire columns at once in Pandas - this is really useful for calculations such as add, subtract, multiply and divide. You can also assign these changes to new columns in order to preserve your original column data. In general, this is done by defining a new column and setting a value to it. \n",
    "\n",
    "For example, if I wanted to define a new column called ```new_column``` and set every value in the column to 0 (zero):\n",
    "- ```df['new_column'] = 0```\n",
    "\n",
    "Pandas has a number of built in functions for adding, subtracting, dividing and multiplying all values in a column by a _scalar value_. This can also be done in a number of alternative ways.\n",
    "\n",
    "For example, if I wanted to add 5 to all values in the Petal Length column (in a new column called ```'Petal Length + 5'```, either:\n",
    "- ```df['Petal Length + 5'] = df['Petal Length'] + 5```\n",
    "- ```df['Petal Length + 5'] = df['Petal Length'].add(5)```\n",
    "\n",
    "If I wanted to add 5 to all values in the Petal Length column (in a new column called ```'Petal Length - 5'```, either:\n",
    "- ```df['Petal Length - 5'] = df['Petal Length'] - 5```\n",
    "- ```df['Petal Length - 5'] = df['Petal Length'].sub(5)```\n",
    "\n",
    "If I wanted to multiply all values in the Petal Length column by 5 (in a new column called ```'Petal Length * 5'```, either:\n",
    "- ```df['Petal Length * 5'] = df['Petal Length'] * 5```\n",
    "- ```df['Petal Length * 5'] = df['Petal Length'].mult(5)```\n",
    "\n",
    "If I wanted to divide all values in the Petal Length column by 5 (in a new column called ```'Petal Length / 5'```, either:\n",
    "- ```df['Petal Length / 5'] = df['Petal Length'] / 5```\n",
    "- ```df['Petal Length / 5'] = df['Petal Length'].div(5)```\n",
    "\n",
    "In all the cases above, the two lines of code will produce the equivalent output, however the built in functions (the second option in all cases) also provides functionality to fill values if there is missing data within the dataframe.\n",
    "\n",
    "In the cell below, subtract 3.0 from the ```'Sepal Length'``` column and save the output to a new column called ```'SepalLength-3'```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create a new column 'SepalLength-3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, columns can be added, subtracted, multiplied and divided together in order to perform column-wise calculations. \n",
    "\n",
    "For example: \n",
    "- ```df['add_col'] = df['columnA] + df['columnB']```\n",
    "- ```df['subtract_col'] = df['columnA] - df['columnB']```\n",
    "- ```df['multiply_col'] = df['columnA] * df['columnB']```\n",
    "- ```df['divide_col'] = df['columnA] / df['columnB']```\n",
    "\n",
    "\n",
    "A good example in this case would be to calculate the approximate area of a petal (with the incorrect assumption that a petal is rectangular!) \n",
    "\n",
    "In the cell below, create a new column called ```'PetalArea'``` that is created by multiplying ```'Petal Length'``` and ```'Petal Width'``` together:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a column called 'Petal Area'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Selecting data using ```.loc``` and ```.iloc```**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using more Pandas built-in functions, you can select data out of the larger dataframe based on the index value, the integer row or column value or based on a specific condition.\n",
    "\n",
    "The first of these functions is the ```.iloc``` function. This function selects data from the dataframe based on its integer position on each axis and looks like this generally:\n",
    "\n",
    "```df.iloc[row_value, column_value (if needed)]```\n",
    "\n",
    "If I wanted to select a specific row from our DataFrame - say row 3 - I could run the code ```df.iloc[3]``` and because we want the data from all columns there is no need to specify a column value.\n",
    "\n",
    "If I wanted to select a specific column from the dataframe - column 2 for example - I would have to run ```df.iloc[:, 2]```, as a row_value needs to be specified. But in this case, we can use ```:``` to mean 'all rows', whilst the ```2``` selects the correct column.\n",
    "\n",
    "In the cell below, use the ```.iloc``` function to select the value within the Iris dataframe with index=76, column=3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select Row 76, Column 3 using .iloc, it should return a single value (1.4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```.iloc``` can also be used to select larger slices of the DataFrame based upon the **integer** position in the axis. \n",
    "\n",
    "For example, if we wanted to choose multiple rows - we can pass a list (ie. ```[1,23,41,56]```) to the row_value parameter, and the same can be done for column values. We can also choose numbers within a range (by using ```:``` again!). \n",
    "\n",
    "For example, if we wanted to return all rows between row _a_ and row _b-1_, we would run ```df.iloc[a:b]```, and again this can work for column values as well. \n",
    "\n",
    "In the cell below, return all rows between row 45 and row 55:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return all rows between cell 45 and cell 55\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ```.loc[]``` function can also be used to select or set values from rows or columns based on **labels**. It follows a similar code format to ```.iloc[]``` in that the use of the function generally looks like this:\n",
    "\n",
    "```df.loc[row_value, column_value]```\n",
    "\n",
    "If you pass as integer to the ```.loc``` method (as you would the ```.iloc``` method), the method will assume the integer is the label - not an integer position (however, on the rows axis you can use an integer if it corresponds to the index label)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like the ```.iloc``` method, the ```.loc``` method can have a list passed to it to return data corresponding to multiple labels.\n",
    "\n",
    "For example, if we wanted to select all the rows from the 'Species' column, we can use ```df.loc[:, 'Species']```. \n",
    "\n",
    "Run this in the cell below to see the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the Species column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, return the 'Petal Length' column between the rows 10 and 20:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return rows between 10 and 20 of the Petal Length column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the ```.iloc``` method is great for returning rows of a DataFrame based on a condition. In this case, rather than a row_value we pass a condition such as ```df['Species']=='Iris-virginica'```. \n",
    "\n",
    "Therefore, if we wanted to find all the rows that contain 'Iris-virginica' as the 'Species' we could run:\n",
    "\n",
    "```df.loc[df['Species']=='Iris-virginica']```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this in the cell below to see the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the code and see the output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, select all the rows in which Petal Length is larger than 5.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select all rows where Petal Length greater than 5.5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Using ```groupby``` and ```agg```**\n",
    "\n",
    "When exploring a dataset, the ```groupby``` function is useful as it allows us to group our data based on different features within the dataset itself. \n",
    "\n",
    "You can group the dataset based on the values found in a specific column of the dataset. For example, if we wanted to group the dataframe based on values in a column called 'Name', we would run ```df.groupby('Name')```. \n",
    "\n",
    "Within the Iris dataset that we are working on, we could try to group based on the 'Species' column. The code to do this can be found in the cell below - run it to see what is returned. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.groupby('Species')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, as you can see, rather than returning the grouped data, it has returned a _DataFrameGroupBy_ object. This shows that the groupby function has worked, however it won't return the data until it knows what we want to do with it - and this is where **aggregation** functions come in.\n",
    "\n",
    "There are a number of built-in aggregation functions that can be used alongside ```df.groupby``` in order to return a dataframe of the results, such as:\n",
    "- ```count()``` - count the number of values per 'group'.\n",
    "- ```sum()``` - sum the values of another feature (column) per group. ie. add all values together in a single group.\n",
    "- ```mean()``` - take the mean of values of another feature (column) per group.\n",
    "- ```median()``` - take the median of values of another feature (column) per group\n",
    "\n",
    "For example, in the cell below, the code will return a dataframe that counts the number of occurences of each Species in the Iris dataset, run it below to see the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Species').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, because be have not specified a feature (column) to run the aggregate function on, the ```count()``` function is applied to all columns in the dataframe. In order to apply this to a specific column, we can use Pandas indexing to specify the column we would like to use. \n",
    "\n",
    "For example, ```df.groupby('Species')['Petal Width'].count()```. As can be seen in the cell below, this returns a Series object, with the count specifically referring to the column specified. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Species')['Petal Width'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is also how we would approach using the other aggregate functions. If, for example, we wanted to find the mean of the 'Sepal Length' by 'Species' within the Iris dataset, the code would be in the same format: ```df.groupby('Species')['Sepal Length'].mean()```\n",
    "\n",
    "In the cell below, find the median value of 'Petal Width' by 'Species' using the ```groupby``` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the median value of Petal Width by Species\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**```.agg()``` Function**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further to this, the ```.agg()``` function can be used to both apply multiple functions at once or apply new functions that we have created in the same way that we applied ```mean()``` and ```median``` to the data above. It can also be used in conjunction with the ```groupby()``` function. \n",
    "\n",
    "In order to apply multiple functions to the data, we can pass a list to the ```.agg()``` function with the string name of the functions you would like to apply.\n",
    "\n",
    "For example, if we wanted to find the minimum and maximum values of 'Petal Length' of each 'Species' in the dataset, we can run the code:\n",
    "\n",
    "```df.groupby('Species')['Petal Length'].agg(['min', 'max'])```\n",
    "\n",
    "Run this code in the cell below to see the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the code to get the Minimum and Maximum values found in 'Petal Length'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, we can also apply diffrent aggregations to different columns all at once, and we can do this by passing a dictionary object to the ```.agg()``` function.\n",
    "\n",
    "The format of the dictionary would be similar to this example:\n",
    "```\n",
    "example_dict = {\n",
    "                'column_name' : function,\n",
    "                'column_name2' : [can, also, pass, a, list, of, functions]\n",
    "                }\n",
    "```\n",
    "As you can see in the example, by using a dictionary we can pass different functions to different columns, but also apply multiple functions to a single column all at the same time. For example, if we wanted to find the mean of the 'Petal Width' per species, but also wanted to find the minimum and maximum values found in the 'Sepal Length' column per Species, we could run:\n",
    "\n",
    "```\n",
    "df.groupby('Species').agg(\n",
    "            {\n",
    "            'Petal Width': 'mean',\n",
    "            'Sepal Length': ['min', 'max']\n",
    "            }\n",
    "            )\n",
    "```\n",
    "Run this code in the cell below to find the output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this method, in the cell below, find the:\n",
    "- sum of 'Petal Width' values per 'Species'\n",
    "- mean and median of the 'Sepal Length' values per Species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the above values in this cell\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ```.agg()``` function does not need to be used in conjunction with ```groupby``` and can be used and applied to the entire dataset at once. For example, to find the minimum value and mean of each column, we could run: ```df.agg(['min', 'mean'])``` passing a list in the same way we did above to the grouped data.\n",
    "\n",
    "Run this code in the cell below to see the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the same code format seen above (ie. passing a dictionary) - in the cell below, find:\n",
    "- sum of 'Petal Width' values\n",
    "- mean and median of the 'Sepal Length'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the values listed above (hint: apply .agg directly to the df, no need to use groupby - you can use the same dictionary as above)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, the ```.agg()``` function, allows us to pass our own custom functions (or functions from other packages such as ```numpy```) and return the answers as we have done with  'min', 'median' and 'sum' in the previous examples, but we won't be needing this for now.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will look at ```.apply()``` and ```lambda``` functions\n",
    "\n",
    "### ```.apply()``` and ```lambda``` functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ```.apply()``` function can be used to apply a single function along an axis within a DataFrame. This is a much more efficient way of applying a function to every row or column than a ```for loop```. \n",
    "\n",
    "The standard format of an apply function is: ```df.apply(function, axis)```. In this case the axis value can be either 0 (across columns) or 1 (across rows).\n",
    "\n",
    "A good example of this for the iris dataset would be to create a new column in which the 'Species' column is converted to an integer, for example:\n",
    "- 'Iris-setosa' = 1\n",
    "- 'Iris-versicolor' = 2\n",
    "- 'Iris-virginica' = 3\n",
    "\n",
    "One way to do this would be to loop through the rows of the dataframe using a ```for loop```, but this is very inefficient. In the cell below there is code to do this - run the cell below to see how long this takes:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "for ind in df.index: # loop through the indexes of the dataframe - i.e. through each row:\n",
    "    if df.loc[ind, 'Species']=='Iris-setosa': # use .loc function to identify value at row=ind (index) and column 'Species\n",
    "        df.loc[ind, 'SpeciesInteger']=1\n",
    "    if df.loc[ind, 'Species']=='Iris-versicolor':\n",
    "        df.loc[ind, 'SpeciesInteger']=2\n",
    "    if df.loc[ind, 'Species']=='Iris-virginica':\n",
    "        df.loc[ind, 'SpeciesInteger']=3\n",
    "end_time = time.time()\n",
    "print(end_time - start_time, 'seconds') # time the function and print\n",
    "\n",
    "# output the dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, it doesn't take very long. But the larger a dataset becomes, the more important the efficiency! \n",
    "\n",
    "The function below performs the same actions as the cell above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_species_integer(species):\n",
    "    if species=='Iris-setosa':\n",
    "        return 1\n",
    "    if species=='Iris-versicolor':\n",
    "        return 2\n",
    "    if species=='Iris-virginica':\n",
    "        return 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be applied using the ```.apply()``` function to create a new DataFrame column. \n",
    "\n",
    "To apply the ```.apply()``` function to each row - use code of the format:\n",
    "- ```df['new_column_name'] = df['original_column'].apply(function)```\n",
    "\n",
    "In this case we have sliced the dataframe using df['original_column'] to apply the function to only the column we want, but its also possible to apply the ```.apply()``` function to the whole dataframe using just ```df.apply()```\n",
    "\n",
    "In the cell below, given that:\n",
    "- new_column_name = 'SpeciesInteger_Apply'\n",
    "- original_column = 'Species'\n",
    "- function = create_species_integer\n",
    "\n",
    "delete the comment '#TYPE CODE HERE' and replace it with the code in the format above to create a new 'SpeciesInteger_Apply' column using the ```.apply()``` function. When you run the function, the time and df will be returned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# TYPE CODE HERE (Replace this comment with your code)\n",
    "\n",
    "end_time = time.time()\n",
    "print(end_time - start_time)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**lambda functions**\n",
    "\n",
    "In Python, a lambda function is a small anonymous function that can take any number of arguments, but can only contain one expression.\n",
    "\n",
    "This can be a useful way of applying a transformation to a variable or some data in a single line.\n",
    "\n",
    "For example, the expression: \n",
    "\n",
    "```x = lambda a: a + 10```\n",
    "\n",
    "Defines a function ```x``` which adds 10 to whatever argument is passed to the function.\n",
    "\n",
    "The lambda function can be used in conjunction with ```.apply()``` to make simple transformations to data 'row-by-row'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, if we wanted to create a column that contained the value of 'Sepal Length' multiplied by 10 (we know from before in **Column-wise operations on Pandas Dataframe** that there are easier ways to do this, but this works as an example), we could use the code:\n",
    "\n",
    "```df['SepalLength_times_10'] = df['Sepal Length'].apply(lambda a: a*10)```\n",
    "\n",
    "Run this code in the cell below to see the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run code here to create 'SepalLength_times_10' column, remember to add a separate line with 'df' on it to see the dataframe output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, this does as we wanted. In the code itself, the ```.apply()``` function applies the lambda function to every value on each row found in the 'Sepal Length' column of the dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Using Pandas "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a number of libraries that are used for visualising data in Python. The most common and the most well-taught is ```matplotlib```. However, packages like ```plotly.express``` and ```seaborn``` are extremely useful for making quick plots as well. \n",
    "\n",
    "Using the Iris dataset we can make a number of visualisations and plots to better understand the data.\n",
    "\n",
    "For example, we could plot 'Petal Length' against 'Petal Width' to see if there is a correlation between the two. \n",
    "\n",
    "To do this, Pandas has built-in functions that work alongside ```matplotlib``` to easily create plots. \n",
    "\n",
    "But first, we must import the library. In the cell below, run ```import matplotlib.pyplot as plt``` to import the matplotlib package and alias it with ```plt```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import matplotlib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can use the in-built pandas function ```df.plot()``` to visualise the data and plot with ```matplotlib```. \n",
    "\n",
    "```df.plot()``` takes the arguments _x_, _y_ and _kind_. Where:\n",
    "- _x_ = column label of the data on the x axis\n",
    "- _y_ = column label of the data on the y axis.\n",
    "- _kind_ = the kind of plot you want ie. 'scatter', 'line', 'bar', 'hist'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore in order to plot a graph of 'Petal Length' against 'Petal Width', use the format ```df.plot(x='x_column', y='y_column', kind)``` in the cell below to plot a graph where:\n",
    "- x = 'Petal Length'\n",
    "- y = 'Petal Width'\n",
    "- kind = 'scatter'\n",
    "\n",
    "And run it to see the output: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a graph of Petal Length vs Petal Width\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a really useful function as it allows us to create a simple complete plot with axis labels in a single line.\n",
    "\n",
    "This can also be used in conjunction with Pandas column slicing to create plots from a single column of data. For example, if we wanted to investigate the distribution of the sepal length values (in the form of a histogram), we could run:\n",
    "\n",
    "```df['Sepal Length'].plot(kind='hist')```\n",
    "\n",
    "The ```df['Sepal Length']``` part of the code allows us to pull out the column we want, and then apply the ```.plot()``` function to it. Run the code above in the cell below to see the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a histogram of the Sepal Length values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that _kind_ can take the value 'box', create a boxplot of the distribution of the values found in 'Sepal Width' in the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a boxplot of 'Sepal Width'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, other libraries can be very useful for creating more complicated or interactive plots.\n",
    "\n",
    "For example, in the Iris dataset, visualising the group that the data point belongs to is also very useful to see on a plot. With the package ```plotly.express``` you can do this by using code in the format:\n",
    "\n",
    "```\n",
    "import plotly.express as px\n",
    "fig = px.scatter(dataframe, x= x_column_name, y= y_column_name, color=color_column_name)\n",
    "fig.show()\n",
    "```\n",
    "\n",
    "Using this, you can give each marker a colour based on another column value (and you get an interactive plot as well!).\n",
    "\n",
    "Therefore, if we wanted to plot 'Sepal Length' vs 'Sepal Width' and colour the markers based on the 'Species', we can use this code:\n",
    "```\n",
    "import plotly.express as px \n",
    "fig = px.scatter(df, x='Sepal Length', y='Sepal Width', color='Species')\n",
    "fig.show()\n",
    "\n",
    "```\n",
    "Copy this code into the cell below to see the output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the code into this cell to see the output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, this is now particularly useful for understanding how the 'Species' of the plant is linked to the relationship between 'Sepal Length' and 'Sepal Width'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using ```plotly``` you can then hover over the plot with your mouse to see specific values of the data points, or zoom in on the plot by dragging a box around the area you want to view."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extension Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cells below - use the Titanic dataset to apply what you have learnt above!\n",
    "\n",
    "The Titanic dataset consists of 10 columns:\n",
    "- 'survival': Binary variable for if passenger survived (0=No, 1=Yes)\n",
    "- 'pclass': Ticket class (1=1st, 2=2nd, 3=3rd)\n",
    "- 'sex': Listed sex of the passenger\n",
    "- 'Age': Age in years of the passenger\n",
    "- 'sibsp': No. of siblings/spouses of the passenger aboard the Titanic\n",
    "- 'parch': No. of parents/children of the passenger aboard the Titanic\n",
    "- 'ticket': Ticket number\n",
    "- 'fare': Passenger fare\n",
    "- 'cabin': Cabin number\n",
    "- 'embarked': Port of Embarkation (C=Cherbourg, Q=Queenstown, S=Southampton)\n",
    "\n",
    "Work through the exercises below to investigate the Titanic data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Import the Titanic dataset. It has the path 'Titanic.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Titanic Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Display the first 10 rows of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display First 10 rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Create a table that describes the Titanic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe the Titanic Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Add together the number of 'Sibling/Spouses' to the number of 'Parents/Children' to create a new column called 'FamilyMembers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 'FamilyMembers' column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Return the value found at the 120th row of the 'Age' column in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return value at row 120 and column 'Age'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Return a slice of the dataframe containing all columns where 'Pclass' equals 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return all rows where Pclass=3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Return the 'min', 'max' and 'mean' values for the 'Fare' column when the data is grouped by 'Pclass'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return the above values for the 'Fare' column when the data is grouped by 'Pclass'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Use the function:\n",
    "\n",
    "    ```\n",
    "    def create_string_class(class_value):\n",
    "        if class_value==1:\n",
    "            return 'First'\n",
    "        if class_value==2:\n",
    "            return 'Second'\n",
    "        if class_value==3:\n",
    "            return 'Third'\n",
    "\n",
    "    ```\n",
    "\n",
    "    and the ```.apply()``` function on the Pclass column to create a new column called 'Class' that converts each rows Pclass value to a string. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Class column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Create a boxplot of all the values in the 'Age' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a boxplot of Age\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Create a scatter plot of 'Age' vs 'Fare' with the marker colours grouped by 'Class' values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scatter plot\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
